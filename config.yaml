seed: 42
batch_size: 32
max_epochs: 5
learning_rate: 2e-4
lambda_reg: 0.01
scale_factor: 1.0
lora_rank: 4
lora_alpha: 1.0
dropout: 0.1
warmup_steps: 100
unfreeze_layers_after: 2
